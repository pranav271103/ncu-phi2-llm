# NCU Smart LLM (phi2-ncu) â€” Smart LLM Fine-tuned for NCU Tasks

<p align="center">
  <img src="https://huggingface.co/pranav2711/phi2-ncu-model/resolve/main/NCU-Logo.png" alt="NCU Logo" width="350"/>
</p>

> A lightweight, instruction-tuned version of [Microsoft's Phi-2](https://huggingface.co/microsoft/phi-2), customized for use cases and conversations related to The NorthCap University (NCU), India.
> Fine-tuned using LoRA on 1,098 high-quality examples, it's optimized for academic, administrative, and smart campus queries.

---

## Highlights

* **Base Model:** `microsoft/phi-2` (2.7B parameters)
* **Fine-tuned Using:** Low-Rank Adaptation (LoRA) + PEFT + Hugging Face Transformers
* **Dataset:** University questions, FAQs, policies, academic support queries, smart campus data
* **Training Environment:** Google Colab (T4 GPU), 4 epochs, batch size 1, no FP16
* **Final Format:** Full model weights (`.safetensors`) + tokenizer

---

## Model Access

| Platform           | Access Method                                                               |
| ------------------ | --------------------------------------------------------------------------- |
| Hugging Face       | [phi2-ncu-model](https://huggingface.co/pranav2711/phi2-ncu-model)          |
| Hugging Face Space | [Live Chatbot Demo](https://huggingface.co/spaces/pranav2711/phi2-ncu-chat-space) |
| Ollama (Offline)   | `ollama create phi2-ncu -f Modelfile` *(self-hosted only)*                  |

---

##  Try It Online

### Gradio Web Chat (Hugging Face Space) (Runs Slow because of free CPU Hardware)

```bash
ðŸ‘‰ Visit: https://huggingface.co/spaces/pranav2711/phi2-ncu-chat-space
```

* Built using `Gradio`, deployed on Hugging Face Spaces

---

## How to Use Locally (Hugging Face Transformers)

```bash
pip install transformers accelerate peft
```

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel, PeftConfig

# Load adapter config
adapter_path = "pranav2711/phi2-ncu-model"
base_model = "microsoft/phi-2"

# Load tokenizer and base
tokenizer = AutoTokenizer.from_pretrained(base_model)
model = AutoModelForCausalLM.from_pretrained(base_model, device_map="auto")

# Load fine-tuned adapter
model = PeftModel.from_pretrained(model, adapter_path)

# Inference
input_prompt = "### Question:\nHow can I apply for re-evaluation at NCU?\n\n### Answer:"
inputs = tokenizer(input_prompt, return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=200)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

---

## How to Use with Ollama (Offline)

> This works only **locally** via `ollama create` and **not yet shareable** as public Ollama model hub is restricted.

### Folder Structure

```
phi2-ncu/
â”œâ”€â”€ Modelfile
â””â”€â”€ model/
    â”œâ”€â”€ model.safetensors
    â”œâ”€â”€ config.json
    â”œâ”€â”€ tokenizer.json
    â”œâ”€â”€ tokenizer_config.json
    â”œâ”€â”€ vocab.json
    â”œâ”€â”€ merges.txt
```

### Steps

```bash
ollama create phi2-ncu -f Modelfile
ollama run phi2-ncu
```

---

## Example Dataset Format (Used for Training)

```json
{
  "instruction": "How do I get my degree certificate?",
  "input": "I'm a 2023 BTech passout from CSE at NCU.",
  "output": "You can collect your degree certificate from the admin block on working days between 9AM and 4PM. Carry a valid ID proof."
}
```

Formatted as:

```
### Question:
How do I get my degree certificate?
I'm a 2023 BTech passout from CSE at NCU.

### Answer:
You can collect your degree certificate...
```

---

## Training Strategy

* Used `LoRA` with rank=8, alpha=16
* Tokenized to max length = 512
* Used `Trainer` with `fp16=False` to avoid CUDA AMP issues
* Batch size = 1, Epochs = 4
* Trained on Google Colab (T4), saving final full weights

---

## License

[Apache 2.0](https://huggingface.co/pranav2711/phi2-ncu-model/resolve/main/LICENSE)

## About NCU

**The NorthCap University**, Gurugram (formerly ITM University), is a multidisciplinary university with programs in engineering, management, law, and sciences.

This model was created as part of a research initiative to explore AI for academic services, campus automation, and local LLM deployments.

## Contribute

Have better FAQs or data? Want to train on your college corpus? Fork the repo or raise a PR at:

ðŸ‘‰ [https://github.com/pranav2711/ncu-smartllm](https://github.com/pranav2711/ncu-smartllm)
